{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshSonaiya/DL/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wse7t1Oek8M5"
      },
      "source": [
        "**CONVOLUTION NEURAL NETWORKS (CNNs):**\n",
        "\n",
        "Convolutional Neural Networks (CNNs) are a class of deep neural networks specifically designed for processing structured grid data like images. They automatically learn important features like edges, textures, and patterns in various images.\n",
        "\n",
        "Types of Images :\n",
        "\n",
        "1) Gray Scale Images: Single-channel images where each pixel represents intensity, often with shape (28x28x1) for simple images like digits.\n",
        "\n",
        "2) RGB Images: Three-channel images where each pixel has three values corresponding to Red, Green, and Blue channels, typically represented as (228x228x3).\n",
        "\n",
        "What are Convolutions ?\n",
        "\n",
        "Convolutions are mathematical operations applied to images to detect patterns such as edges, textures, and other features. These operations are performed by sliding a filter (or kernel) across the image, producing a feature map that highlights specific characteristics.\n",
        "The edges or other patterns can be identified by the change in the intensity values of a pixel that which are the primary feature of an image.\n",
        "\n",
        "Convolution operations are carried out with the help of filters\n",
        "\n",
        "What are filters ?\n",
        "\n",
        "Filters are special matrices that are applied to the image to extract features. Different filters detect different features, such as horizontal, vertical, or diagonal edges, or more complex patterns as the network gets deeper.\n",
        "\n",
        "eg)\n",
        "\n",
        "\n",
        "```\n",
        " [  [-1, -1, -1],\n",
        "    [ 0,  0,  0],\n",
        "    [ 1,  1,  1] ]\n",
        "```\n",
        "This filter helps to identify horizontal edges in the image\n",
        "\n",
        "How ?\n",
        "\n",
        "Image is a grid of intensity values on which features are convoled in order to get a feature map which helps us to identify where Horizontal edges are present.\n",
        "\n",
        "\n",
        "```\n",
        "[ [0, 0, 0, 0, 0, 0],\n",
        "  [0, 0, 0, 0, 0, 0],\n",
        "  [0, 0, 0, 0, 0, 0],\n",
        "  [255, 255, 255, 255,255, 255],\n",
        "  [255, 255, 255, 255, 255, 255],\n",
        "  [255, 255, 255, 255, 255, 255]  ]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "  This is an image and \"\" * \"\" is the convolution operator\n",
        "\n",
        "We place the filter on the image first 3x3 submatrix from the top left corner and multiply elements at the same position i.e.\n",
        "\n",
        "```\n",
        "[  [0 x -1, 0 x -1, 0 x -1],         [ [0, 0, 0],  \n",
        "   [0 x 0,  0 x 0,  0 x 0],       =    [0, 0, 0],\n",
        "   [0 x 1,  0 x 1,  0 x 1]  ]          [0, 0, 0] ]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Then these values are added and the result is the intenity value of the first cell in the feature map similarly values for all the cells of the feature map are calculated which will look like this:\n",
        "\n",
        "\n",
        "```\n",
        "feature_map = [ [0, 0, 0, 0],\n",
        "                [255, 255, 255, 255],\n",
        "                [255, 255, 255, 255],\n",
        "                [0, 0, 0, 0], ]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "Here in cells with 255 + 255 + 255 result is 255 as it is the maximu possible intensity value for an pixel.\n",
        "\n",
        "Similarly we can use different pre defined filters to detect edges in an Image\n",
        "\n",
        "In CNNs, filters are initialized with random values. During training, the network learns by adjusting the filter values (through backpropagation) to better capture features relevant to the task. This process helps CNNs automatically learn the best set of filters for edge detection, textures, and more complex patterns.\n",
        "\n",
        "Checkout deeplizard.com\n",
        "\n",
        "The size of the feature map depends on the image size, filter size, stride, and padding. Without padding, the feature map's size is reduced, calculated as (n - m + 1), but padding adds extra pixels to preserve the image dimensions after convolution.\n",
        "\n",
        "**What is Padding ?**\n",
        "\n",
        "In the above convolution operation example, on applying filter of size (mxm) to an image of size (nxn) the feature map we obtain is of size (n-m+1 , n-m+1). Here the pixels in the boundaries of the grid i.e. first row from top and bottom and first column from left and right are not able to contribute much and it also becomes difficult to detect edges if they are present in these four regions. It also leads to loss of information.\n",
        "\n",
        "In CNNs, padding refers to the addition of extra pixels (usually with a value of zero) around the border of an image before applying a convolution operation. This is done to control the spatial dimensions of the output feature map and to avoid losing information from the edges of the image.\n",
        "\n",
        "An 3 x 3 image after padding becomes a 4 x 4image which looks like :\n",
        "\n",
        "\n",
        "An on this new image filter is applied.\n",
        "\n",
        "```\n",
        "[ [2, 3, 4],                    [ [0, 0, 0, 0],\n",
        "  [220, 223, 224],         =>     [0, 2, 3, 4],  \n",
        "  [2, 3, 4]  ]                    [0, 220, 223, 224],\n",
        "                                  [0, 2, 3, 4] ]\n",
        "\n",
        "```\n",
        "\n",
        "**Types of Padding:**\n",
        "\n",
        "1. Valid Padding (padding='valid'):\n",
        "  \n",
        "   No padding is applied.\n",
        "   \n",
        "   The output size is reduced based on the filter size.\n",
        "   \n",
        "   Formula for output size: (n - m + 1) (n - m + 1).\n",
        "\n",
        "2. Same Padding (padding='same'):\n",
        "   \n",
        "   Padding is applied to maintain the input and output size the same (or as close as possible).\n",
        "  \n",
        "   Extra rows/columns are added to the borders of the image.\n",
        "   \n",
        "   Formula for output size: nxn, i.e., the output has the same dimensions as the input.\n",
        "\n",
        "In keras we can apply choose if we want to apply padding or not\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ohdzH6I_k8M9",
        "outputId": "88aaf876-c66d-431d-c17e-9fc234b946fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "! pip install tensorflow\n",
        "! pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xEGZ5IWqk8M_"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense,Conv2D,Flatten,MaxPooling2D\n",
        "from keras import Sequential\n",
        "from keras.datasets import mnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xYLf15Iak8M_"
      },
      "outputs": [],
      "source": [
        "#Load the MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ouaXGuIFk8NA"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# CNN without padding\n",
        "# Here 32 represents filters (learnable kernels), each detecting different features.\n",
        "# (3,3) is the size of the filter and relu activation function is used to convert all\n",
        "# negative values to zero\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
        "\n",
        "# Flattens the output of the previous convolutional layers (2D feature maps) into a 1D vector,\n",
        "# to be fed into the fully connected layers.\n",
        "model.add(Flatten())\n",
        "\n",
        "# Adds a fully connected (dense) layer with 128 neurons.\n",
        "# Activation function is ReLU to add non-linearity.\n",
        "# This layer learns high-level features from the flattened vector.\n",
        "model.add(Dense(128,activation='relu'))\n",
        "\n",
        "# Output layer with 10 neurons, one for each class in a 10-class classification problem (e.g., digits 0-9 in MNIST).\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "LcdmYHNjk8NA",
        "outputId": "fd60cb1c-ee5b-45fa-bd90-3bbdded53572"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m22\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15488\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m1,982,592\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">22</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15488</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,982,592</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,002,698\u001b[0m (7.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,002,698</span> (7.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,002,698\u001b[0m (7.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,002,698</span> (7.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "# padding='same': Padding is added so the output feature map has the same size as the input.\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu'))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same', activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "xrjB-aSqnSBe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "CWMA2EwwnWSX",
        "outputId": "2f65de3d-b27b-432d-9287-529e5b932c7f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │       \u001b[38;5;34m3,211,392\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">3,211,392</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,231,498\u001b[0m (12.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,231,498</span> (12.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,231,498\u001b[0m (12.33 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,231,498</span> (12.33 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkYnOZHmk8NB"
      },
      "source": [
        "**What are Strides?**\n",
        "\n",
        "In convolution operations, the stride refers to how much the filter (kernel) shifts across the input image. When the stride is set to 1, the filter shifts by one position at a time, moving across the entire input image both horizontally (left to right) and vertically (top to bottom).\n",
        "\n",
        "We can change the stride to a value of our choice. On increasing the value of stride the size of feature map further reduces which is given by [(n-m)/s + 1] and in case of padding [ (n + 2p - m)/s  + 1]\n",
        "\n",
        "**What are its effects?**\n",
        "\n",
        "A stride value of 1 helps to get precise results as there is no losso of information if padding is applied with it. But this increases the computation complexity and training time.\n",
        "\n",
        "A stride value greater than 1 can help to reduce the computational complexity / cost as well reduce the time for training. Another benefit is that it can help to reduce overfitting. But here the issue is precision is less as compared to\n",
        "in the case of stride = 1. Also we need to check if stride greater than 1 helps to consider all the cell of the image or not eg image of size 7x6.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OzqHeV_ik8NA"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "# strides=(2,2) to shift the filter by 2 pixels in both horizontal and vertical directions.\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='same',strides=(2,2), activation='relu'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "XNepH_SZk8NB",
        "outputId": "d1089b45-9431-4bbe-aabf-e14a2699e519"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,770\u001b[0m (335.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,770</span> (335.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,770\u001b[0m (335.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,770</span> (335.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Problems in Convolution Operation:**\n",
        "\n",
        "1) **Memory Consumption:**\n",
        "\n",
        "   **Issue:** Convolutional Neural Networks (CNNs) require significant memory, especially as the depth (number of layers) and size of feature maps increase. Each convolutional layer produces multiple feature maps, which need to be stored and processed during forward and backward propagation.\n",
        "\n",
        "   **Why It Happens:** The need for large numbers of filters, high-resolution input images, and deep network architectures contribute to the memory consumption. Intermediate feature maps and the gradients during backpropagation are also stored, which increases memory usage.\n",
        "\n",
        "   **Impact:** This can result in hardware limitations, especially when training on large datasets or high-resolution images, making it difficult to train deep CNNs on machines with limited GPU memory.\n",
        "   \n",
        "   **Solutions:**\n",
        "\n",
        "   **Use Stride > 1**\n",
        "\n",
        "   **Use of pooling layers**\n",
        "   \n",
        "   **Batching:** Training on smaller batches of images can also reduce memory requirements.\n",
        "\n",
        "2) **Translation Variance:**\n",
        "\n",
        " **Issue:** CNNs are not inherently invariant to shifts/translations.\n",
        "\n",
        " Translation Variance refers to the sensitivity of a Convolutional Neural Network (CNN) to shifts or translations of features within an image. In other words, if an object or feature in an image is moved (translated) slightly from its original position, the CNN might fail to recognize it correctly or produce a different response. This happens because the convolution operation detects features based on fixed spatial positions, so even a small change in the feature's position can affect the activation in the convolutional layers.\n",
        "\n",
        " **Why It Happens:** Convolutions apply filters at fixed positions, and if the feature (like an edge or object) moves, it may not align with the learned filters in the same way. This causes the output to vary even though the essential feature remains the same but in a different location.\n",
        "\n",
        " **Impact:** This variance to translations can affect the generalization of CNNs and their ability to accurately detect features irrespective of position in an image.\n",
        "   \n",
        " **Solutions:**\n",
        "\n",
        " **Data Augmentation**\n",
        "  \n",
        " **Pooling Layers**"
      ],
      "metadata": {
        "id": "ub_rOqwKt6RZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is Pooling ?\n",
        "\n",
        "Pooling in Convolutional Neural Networks (CNNs) reduces the spatial dimensions (width and height) of the feature maps. Pooling operations help make the network computationally efficient, reduce overfitting, and make the network invariant to small shifts and distortions (translation invariance).\n",
        "\n",
        "The main idea of pooling is to downsample the input feature maps, summarizing the most important information and discarding unnecessary details.\n",
        "\n",
        "This helps to solve the problem of translation variance as well as memory consumption. HOW ????\n",
        "\n",
        "Suppose we have a 4x4 image and we want to apply pooling:\n",
        "\n",
        "![pooling.png](data:image/png;base64,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)\n",
        "\n"
      ],
      "metadata": {
        "id": "EgNIBT4cwae7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Pooling we specify the size of pooling window, the type of pooling and the stride we want to use.\n",
        "\n",
        "The above example illustrates 2x2 Max Pooling with stride 1 meaning that the Pooling window is of size 2x2 so the image is divide equally in regions of 2x2 grid, stride = 1 means the window shifts one pixel at a time and Max Pooling is the type of pooling where we choose the maximum value from the neighbouring cells in the pooling window.\n",
        "\n",
        "The output feature map's size depends on the pooling window size, stride and the type of pooling and is given by:\n",
        "\n",
        "Output size = [(n - pooling_window_size) / stride + 1]\n",
        "\n",
        "\n",
        "This solves the problem of memory consumption as pooling layers reduce the dimensions of feature maps, which directly decreases the number of parameters and the memory required to store the feature maps.\n",
        "\n",
        "It also prevents information loss as max pooling and other types of pooling retain the most important or dominant information by selecting the maximum (in the case of max pooling) value from each region. This way, key high-level features, such as edges or patterns, are preserved even as the spatial dimensions are reduced. The pooling operation ensures that only the most significant feature in each region is kept, making the model focus on important details.\n",
        "\n",
        "Pooling introduces spatial invariance and solves the problem of Translation Variance by summarizing features over larger regions, meaning that the exact location of the feature is less important. For example, even if a feature (like an edge or texture) moves slightly within a region, max pooling will still capture the highest activation from that region. This reduces the model's sensitivity to small translations or shifts in the input, making it better at recognizing objects regardless of their position in the image."
      ],
      "metadata": {
        "id": "nM0jAk3kx11U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Types of Pooling\n",
        "\n",
        "1.  Average Pooling\n",
        "2.  Max Pooling\n",
        "3. Global Pooling (both Max and Average)\n"
      ],
      "metadata": {
        "id": "NVYaL36Ez3K_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "u-ka60Cyk8NB"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu', input_shape=(28,28,1)))\n",
        "\n",
        "\n",
        "# MaxPooling reduces the size of the feature maps by downsampling. A 2x2 pool size is used with a stride of 2,\n",
        "# which reduces the spatial dimensions of the input by half (e.g., 28x28 becomes 14x14).\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=2, padding='valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(10,activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "xGjemY2Szozf",
        "outputId": "92907bdd-4745-48bb-b266-49ffd5034cbd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │           \u001b[38;5;34m9,248\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m800\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m102,528\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">102,528</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m113,386\u001b[0m (442.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,386</span> (442.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m113,386\u001b[0m (442.91 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">113,386</span> (442.91 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advantages of Pooling\n",
        "\n",
        "1. Reduced Memory usage\n",
        "2. Transalation and Spatial Invariant\n",
        "3. Enhanced Features  (Only in case of Max Pooling)\n",
        "4. No Need of training"
      ],
      "metadata": {
        "id": "pX6iXFOZ2OiY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Disadvantage of Pooling\n",
        "\n",
        "1. **Loss of Information**: Pooling operations, especially Max Pooling, can lead to the loss of important spatial information. By only retaining the maximum (or average) value, other potentially significant features may be discarded.\n",
        "\n",
        "2. **Reduced Spatial Resolution**: Pooling reduces the spatial dimensions of the feature maps, which can make it more challenging for the network to capture fine details in the input images.\n",
        "\n",
        "3. **Sensitivity to Outliers**: In Max Pooling, the presence of outliers can disproportionately influence the output. A single high value in a pooling window can lead to significant changes in the feature map, potentially skewing the learned representations.\n",
        "\n",
        "4. **Translation Invariance Limitations**: While pooling does help with translation invariance, it can also make the model less sensitive to small translations of features. This may be detrimental in cases where precise localization of features is essential such as in Image Segmentation tasks.\n",
        "\n",
        "5. **Difficulty in Capturing Global Context**: Pooling may not effectively capture global context, particularly in scenarios where the relationships between distant pixels are crucial for understanding the overall image."
      ],
      "metadata": {
        "id": "fsjypVxf3hyZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        " Explored key concepts of Convolutional Neural Networks (CNNs), including convolution operations, where filters extract important features like edges. Stride and padding control the size and precision of feature maps, with larger strides reducing map size but at the cost of precision. Pooling layers (such as Max Pooling) reduce feature map size to save memory, retain high-level features, and address translation variance, making CNNs more spatially invariant."
      ],
      "metadata": {
        "id": "kmsRkgdD34bF"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}